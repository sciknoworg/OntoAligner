{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THzx_Fsl_a2_"
   },
   "source": [
    "![logo](https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/images/logo-with-background.png)\n",
    "\n",
    "[![PyPI version](https://badge.fury.io/py/OntoAligner.svg)](https://badge.fury.io/py/OntoAligner)\n",
    "[![PyPI Downloads](https://static.pepy.tech/badge/ontoaligner)](https://pepy.tech/projects/ontoaligner)\n",
    "![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)\n",
    "[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit)](https://github.com/pre-commit/pre-commit)\n",
    "[![Documentation Status](https://readthedocs.org/projects/ontoaligner/badge/?version=main)](https://ontoaligner.readthedocs.io/)\n",
    "[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](MAINTANANCE.md)\n",
    " [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.14533133.svg)](https://doi.org/10.5281/zenodo.14533133)\n",
    "\n",
    "- **Documentation website**: [https://ontoaligner.readthedocs.io/index.html](https://ontoaligner.readthedocs.io/index.html)\n",
    "- **Resource Paper**: [https://doi.org/10.1007/978-3-031-94578-6_10](https://doi.org/10.1007/978-3-031-94578-6_10)\n",
    "\n",
    "\n",
    "--------\n",
    "\n",
    "# Deep Dive into OntoAligner Modules 1 (Parser, Encoder, Evaluator and Exporter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbpUhJV_oWxM"
   },
   "source": [
    "Before diving lets have a look at a big picture of how OA models should operate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jULJKZIXoVTn"
   },
   "source": [
    "\n",
    "![](https://mdpi-res.com/futureinternet/futureinternet-02-00238/article_deploy/html/images/futureinternet-02-00238-g001.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLXlo9m8ofKU"
   },
   "source": [
    "**Key components to consider when developing an OA:**\n",
    "- How should I load the source ontology and extract desirable data from it to do the alignment? `concepts` (classes), or `concepts`+`childs` (classes and child classes) or ...\n",
    "- How to prepare the input of OA models?\n",
    "- Do I need to do the post-processing of alignments after the aligning the ontologies? applying threshold based filtering, ... --> ``topic of next tutorial``!\n",
    "- How to do the evaluation?\n",
    "- How store the results?\n",
    "\n",
    "--------\n",
    "Contents of this tutorial:\n",
    "1. How the ``Parser`` module works?\n",
    "2. What is the ``task`` (or ``OMDataset``) in OntoAligner?\n",
    "3. How the ``Encoder`` module works?\n",
    "4. How the ``Exporter`` module works.\n",
    "5. Putting it all together - A complete workflow with an ``Evaluation``.\n",
    "\n",
    "--------\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 10763,
     "status": "ok",
     "timestamp": 1770409975297,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "7DlIGZXr_aNO"
   },
   "source": [
    "# Install the OntoAligner library. (restart the notebook after installation)\n",
    "!pip install -q ontoaligner numpy>=2.0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "parser_section"
   },
   "source": [
    "---\n",
    "\n",
    "# 1Ô∏è‚É£. How the ``Parser`` module works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "parser_explanation"
   },
   "source": [
    "The **Parser** module is responsible for reading ontology files (OWL, RDF/XML, etc.) and converting them into a standardized format that OntoAligner can work with. It extracts key information such as:\n",
    "\n",
    "- Entity IRIs (Internationalized Resource Identifiers)\n",
    "- Labels and names\n",
    "- Comments and documentation\n",
    "- Synonyms\n",
    "- Hierarchical relationships (parents, children)\n",
    "\n",
    "**Key Parser Classes:**\n",
    "- `BaseOntologyParser` - Base parser for generic ontologies where ``GenericOntology`` operates on it to pars ontologies in generic manner.\n",
    "- `BaseAlignmentsParser` - Parses alignment/matching/reference files that are being used for evaluation.\n",
    "- Domain-specific parsers for OAEI benchmark tasks\n",
    "\n",
    "A source and target ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6341,
     "status": "ok",
     "timestamp": 1770410048468,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "parser_example",
    "outputId": "56f7f26b-c8ef-4744-dc85-c0de554022b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2744it [00:00, 13836.60it/s]\n",
      "3304it [00:00, 5829.51it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9102/9102 [00:00<00:00, 32444.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source entities parsed: 2743\n",
      "Target entities parsed: 3304\n",
      "Alignments parsed: 1516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ontoaligner.ontology import GenericOntology\n",
    "from ontoaligner.base import BaseAlignmentsParser\n",
    "\n",
    "# Initialize parsers\n",
    "ontology_parser = GenericOntology()\n",
    "alignment_parser = BaseAlignmentsParser()\n",
    "\n",
    "# Parse source ontology\n",
    "source_parsed = ontology_parser.parse(\n",
    "    \"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/source.xml\"\n",
    ")\n",
    "\n",
    "# Parse target ontology\n",
    "target_parsed = ontology_parser.parse(\n",
    "    \"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/target.xml\"\n",
    ")\n",
    "\n",
    "# Parse reference alignments\n",
    "alignments_parsed = alignment_parser.parse(\n",
    "    \"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/reference.xml\"\n",
    ")\n",
    "\n",
    "print(f\"\\nSource entities parsed: {len(source_parsed)}\")\n",
    "print(f\"Target entities parsed: {len(target_parsed)}\")\n",
    "print(f\"Alignments parsed: {len(alignments_parsed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1770410066707,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "rue3ZzMYqazb"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1770410082754,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "parser_detail",
    "outputId": "009d88cb-ea94-47ed-98fc-7ebd0b80141f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed view of first source entity:\n",
      "{'childrens': [],\n",
      " 'comment': [],\n",
      " 'iri': 'http://mouse.owl#MA_0000006',\n",
      " 'label': 'head/neck',\n",
      " 'name': 'head/neck',\n",
      " 'parents': [{'iri': 'http://mouse.owl#MA_0002433',\n",
      "              'label': 'anatomic region',\n",
      "              'name': 'anatomic region'}],\n",
      " 'synonyms': []}\n"
     ]
    }
   ],
   "source": [
    "# Examine a parsed entity in detail\n",
    "print(\"\\nDetailed view of first source entity:\")\n",
    "pprint(source_parsed[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1770410088096,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "alignment_detail",
    "outputId": "0a6694a4-2b49-40fc-c3fb-58f4e81213e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample parsed alignments:\n",
      "[{'relation': '=',\n",
      "  'source': 'http://mouse.owl#MA_0002401',\n",
      "  'target': 'http://human.owl#NCI_C52561'},\n",
      " {'relation': '=',\n",
      "  'source': 'http://mouse.owl#MA_0000270',\n",
      "  'target': 'http://human.owl#NCI_C33736'},\n",
      " {'relation': '=',\n",
      "  'source': 'http://mouse.owl#MA_0001951',\n",
      "  'target': 'http://human.owl#NCI_C12715'},\n",
      " {'relation': '=',\n",
      "  'source': 'http://mouse.owl#MA_0002303',\n",
      "  'target': 'http://human.owl#NCI_C52701'},\n",
      " {'relation': '=',\n",
      "  'source': 'http://mouse.owl#MA_0001543',\n",
      "  'target': 'http://human.owl#NCI_C12385'}]\n"
     ]
    }
   ],
   "source": [
    "# Examine parsed alignments\n",
    "print(\"\\nSample parsed alignments:\")\n",
    "pprint(alignments_parsed[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKo6AfVkET1K"
   },
   "source": [
    "# 2Ô∏è‚É£. What is the ``task`` (or ``OMDataset``) in OntoAligner?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbYqlcsLEeg5"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Ontology alignment systems often handle multiple tasks in a benchmark dataset. Each task can be evaluated independently. In OntoAligner, a task typically consists of:\n",
    "* **Source ontology** ‚Äì the first ontology in the alignment.\n",
    "* **Target ontology** ‚Äì the second ontology you want to align to the source.\n",
    "* **Reference or gold standard alignment** (optional) ‚Äì used for evaluation.\n",
    "\n",
    "\n",
    "üí°üí°üí° Explore how two different parsers work together to build up a task (a.k.a OMDataset) [https://ontoaligner.readthedocs.io/developerguide/parsers.html](https://ontoaligner.readthedocs.io/developerguide/parsers.html)\n",
    "\n",
    "\n",
    "**Why this matter?** OntoAligner makes it easy to modularize an OA task for easy experimentations, for example in OntoAligner's workflow."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6907,
     "status": "ok",
     "timestamp": 1770410343733,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "K5UsS_KHIVw8",
    "outputId": "75a12dd6-d239-4aca-b1d1-d4e51b810b95"
   },
   "source": [
    "from ontoaligner.ontology import GenericOMDataset\n",
    "\n",
    "task = GenericOMDataset()\n",
    "\n",
    "dataset = task.collect(\n",
    "    source_ontology_path=\"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/source.xml\",\n",
    "    target_ontology_path=\"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/target.xml\",\n",
    "    reference_matching_path=\"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/reference.xml\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1770410217225,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "K87hCb86JU0H",
    "outputId": "d1b3a890-70de-4b11-cb1f-a5c60f799e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source Ontology Entity:\n",
      "{'childrens': [],\n",
      " 'comment': [],\n",
      " 'iri': 'http://mouse.owl#MA_0000001',\n",
      " 'label': 'mouse anatomy',\n",
      " 'name': 'mouse anatomy',\n",
      " 'parents': [],\n",
      " 'synonyms': []}\n"
     ]
    }
   ],
   "source": [
    "# Inspect a source ontology entity\n",
    "print(\"\\nSource Ontology Entity:\")\n",
    "pprint(dataset['source'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1770410374938,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "_BM1t2AVjMfx",
    "outputId": "c83deb0e-4e07-4933-a41b-3dbeea6e81bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Ontology Entity:\n",
      "{'childrens': [{'iri': 'http://human.owl#NCI_C12680',\n",
      "                'label': 'Body_Region',\n",
      "                'name': 'Body_Region'},\n",
      "               {'iri': 'http://human.owl#NCI_C12919',\n",
      "                'label': 'Organ_System',\n",
      "                'name': 'Organ_System'},\n",
      "               {'iri': 'http://human.owl#NCI_C13018',\n",
      "                'label': 'Organ',\n",
      "                'name': 'Organ'},\n",
      "               {'iri': 'http://human.owl#NCI_C13236',\n",
      "                'label': 'Body_Fluid_or_Substance',\n",
      "                'name': 'Body_Fluid_or_Substance'},\n",
      "               {'iri': 'http://human.owl#NCI_C21599',\n",
      "                'label': 'Microanatomy',\n",
      "                'name': 'Microanatomy'},\n",
      "               {'iri': 'http://human.owl#NCI_C25444',\n",
      "                'label': 'Cavity',\n",
      "                'name': 'Cavity'},\n",
      "               {'iri': 'http://human.owl#NCI_C32221',\n",
      "                'label': 'Body_Part',\n",
      "                'name': 'Body_Part'},\n",
      "               {'iri': 'http://human.owl#NCI_C33904',\n",
      "                'label': 'Other_Anatomic_Concept',\n",
      "                'name': 'Other_Anatomic_Concept'}],\n",
      " 'comment': [],\n",
      " 'iri': 'http://human.owl#NCI_C12219',\n",
      " 'label': 'Anatomic_Structure_System_or_Substance',\n",
      " 'name': 'Anatomic_Structure_System_or_Substance',\n",
      " 'parents': [],\n",
      " 'synonyms': []}\n"
     ]
    }
   ],
   "source": [
    "# Inspect a target ontology entity\n",
    "print(\"\\nTarget Ontology Entity:\")\n",
    "pprint(dataset['target'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1770410361080,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "ref_alignments",
    "outputId": "d1372b13-af6d-48b6-d36d-81f4b11438e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reference Alignments (first 5):\n",
      "[{'relation': '=',\n",
      "  'source': 'http://mouse.owl#MA_0002401',\n",
      "  'target': 'http://human.owl#NCI_C52561'},\n",
      " {'relation': '=',\n",
      "  'source': 'http://mouse.owl#MA_0000270',\n",
      "  'target': 'http://human.owl#NCI_C33736'},\n",
      " {'relation': '=',\n",
      "  'source': 'http://mouse.owl#MA_0001951',\n",
      "  'target': 'http://human.owl#NCI_C12715'},\n",
      " {'relation': '=',\n",
      "  'source': 'http://mouse.owl#MA_0002303',\n",
      "  'target': 'http://human.owl#NCI_C52701'},\n",
      " {'relation': '=',\n",
      "  'source': 'http://mouse.owl#MA_0001543',\n",
      "  'target': 'http://human.owl#NCI_C12385'}]\n"
     ]
    }
   ],
   "source": [
    "# Inspect reference alignments\n",
    "print(\"\\nReference Alignments (first 5):\")\n",
    "pprint(dataset['reference'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXV6sQE6Iw7o"
   },
   "source": [
    "**Or you can use a dedicated OA dataset module:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2629,
     "status": "ok",
     "timestamp": 1770410391850,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "7hxfQ2wwjA_6",
    "outputId": "390254a3-7aa9-4f4b-9b89-1f7afbad2540"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2744it [00:00, 6365.82it/s]\n",
      "3304it [00:00, 3778.01it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9102/9102 [00:00<00:00, 47764.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info: {'track': 'anatomy', 'ontology-name': 'mouse-human'}\n",
      "Number of source entities: 2737\n",
      "Number of target entities: 3298\n",
      "Number of reference alignments: 1516\n"
     ]
    }
   ],
   "source": [
    "from ontoaligner.ontology.oaei import MouseHumanOMDataset\n",
    "\n",
    "task = MouseHumanOMDataset()\n",
    "\n",
    "dataset = task.collect(\n",
    "    source_ontology_path=\"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/source.xml\",\n",
    "    target_ontology_path=\"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/target.xml\",\n",
    "    reference_matching_path=\"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/reference.xml\"\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset Info: {dataset['dataset-info']}\")\n",
    "print(f\"Number of source entities: {len(dataset['source'])}\")\n",
    "print(f\"Number of target entities: {len(dataset['target'])}\")\n",
    "print(f\"Number of reference alignments: {len(dataset['reference'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FacH6PlJkXBv"
   },
   "source": [
    "The base ``OMDataset`` module structure:\n",
    "\n",
    "```python\n",
    "class OMDataset(ABC):\n",
    "    track: str = \"\"\n",
    "    ontology_name: str = \"\"\n",
    "\n",
    "    source_ontology: Any = None\n",
    "    target_ontology: Any = None\n",
    "\n",
    "    alignments: Any = BaseAlignmentsParser()\n",
    "\n",
    "    def collect(self,\n",
    "                source_ontology_path: str,\n",
    "                target_ontology_path: str,\n",
    "                reference_matching_path: str=\"\") -> Dict:\n",
    "        ....\n",
    "```\n",
    "\n",
    "Read more on OA datasets and tasks definitions at: https://ontoaligner.readthedocs.io/developerguide/parsers.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "encoder_section"
   },
   "source": [
    "---\n",
    "\n",
    "# 3Ô∏è‚É£. How the ``Encoder`` Module Works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "encoder_explanation"
   },
   "source": [
    "As you can see, per class within source or target ontologies we can get high number of information:\n",
    "```\n",
    "{'childrens': [{'iri': 'http://human.owl#NCI_C12680',\n",
    "                'label': 'Body_Region',\n",
    "                'name': 'Body_Region'},\n",
    "               {'iri': 'http://human.owl#NCI_C12919',\n",
    "                'label': 'Organ_System',\n",
    "                'name': 'Organ_System'},\n",
    "               {'iri': 'http://human.owl#NCI_C13018',\n",
    "                'label': 'Organ',\n",
    "                'name': 'Organ'},\n",
    "               {'iri': 'http://human.owl#NCI_C13236',\n",
    "                'label': 'Body_Fluid_or_Substance',\n",
    "                'name': 'Body_Fluid_or_Substance'},\n",
    "               {'iri': 'http://human.owl#NCI_C21599',\n",
    "                'label': 'Microanatomy',\n",
    "                'name': 'Microanatomy'},\n",
    "               {'iri': 'http://human.owl#NCI_C25444',\n",
    "                'label': 'Cavity',\n",
    "                'name': 'Cavity'},\n",
    "               {'iri': 'http://human.owl#NCI_C32221',\n",
    "                'label': 'Body_Part',\n",
    "                'name': 'Body_Part'},\n",
    "               {'iri': 'http://human.owl#NCI_C33904',\n",
    "                'label': 'Other_Anatomic_Concept',\n",
    "                'name': 'Other_Anatomic_Concept'}],\n",
    " 'comment': [],\n",
    " 'iri': 'http://human.owl#NCI_C12219',\n",
    " 'label': 'Anatomic_Structure_System_or_Substance',\n",
    " 'name': 'Anatomic_Structure_System_or_Substance',\n",
    " 'parents': [],\n",
    " 'synonyms': []}\n",
    " ```\n",
    "Which of these informations are going to be used for alignment model input? and what format they should have?\n",
    "\n",
    "Here the **Encoder** module comes into play that converts parsed outputs into textually structured formats in which later steps goes to the alignments models. Textual entity information can be only a class or class accompanied by its parents or childs. **The encoder also responsible for preprocessings.**\n",
    "\n",
    "\n",
    "**Key encoding approaches that we will dive into it here:**\n",
    "* ``ConceptLightweightEncoder``: A basic textual entity representation that only uses class labels.\n",
    "* ``ConceptChildrenLightweightEncoder``: A basic textual entity representation that only uses class labels and childrens.\n",
    "* ``ConceptParentLightweightEncoder``: A basic textual entity representation that only uses class labels and parents.\n",
    "\n",
    "\n",
    "üí°üí° List of Encoders are presented at: https://ontoaligner.readthedocs.io/package_reference/encoders.html\n",
    "\n",
    "üìùüìù Encoders are mostly model independent, for different models we might apply different encoder dependeing what information each aligner wants. But with OntoAligner you can plug and play with existing modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1770411461023,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "encoder_example",
    "outputId": "47fab78d-f54f-46b8-8308-7c7713565334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded source ontology:\n",
      "{'iri': 'http://mouse.owl#MA_0000001', 'text': 'mouse anatomy'}\n",
      "Encoded target ontology:\n",
      "{'iri': 'http://human.owl#NCI_C12219',\n",
      " 'text': 'anatomic structure system or substance'}\n"
     ]
    }
   ],
   "source": [
    "from ontoaligner.encoder import ConceptLightweightEncoder, \\\n",
    "                                ConceptChildrenLightweightEncoder, \\\n",
    "                                ConceptParentLightweightEncoder\n",
    "\n",
    "encoder = ConceptLightweightEncoder()\n",
    "\n",
    "encoded_source_onto, encoded_target_onto = encoder(\n",
    "        source=dataset['source'],\n",
    "        target=dataset['target']\n",
    ")\n",
    "\n",
    "print(\"Encoded source ontology:\")\n",
    "pprint(encoded_source_onto[0])\n",
    "\n",
    "print(\"Encoded target ontology:\")\n",
    "pprint(encoded_target_onto[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1770411462115,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "bgr1DqsauuvK",
    "outputId": "058e2807-0949-476d-c4ae-61f6540649ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded source ontology:\n",
      "{'iri': 'http://mouse.owl#MA_0000001', 'text': 'mouse anatomy  '}\n",
      "Encoded target ontology:\n",
      "{'iri': 'http://human.owl#NCI_C12219',\n",
      " 'text': 'anatomic structure system or substance  body region, other anatomic '\n",
      "         'concept, organ, cavity, organ system, body fluid or substance, '\n",
      "         'microanatomy, body part'}\n"
     ]
    }
   ],
   "source": [
    "encoder = ConceptChildrenLightweightEncoder()\n",
    "\n",
    "encoded_source_onto, encoded_target_onto = encoder(\n",
    "        source=dataset['source'],\n",
    "        target=dataset['target']\n",
    ")\n",
    "\n",
    "print(\"Encoded source ontology:\")\n",
    "pprint(encoded_source_onto[0])\n",
    "\n",
    "print(\"Encoded target ontology:\")\n",
    "pprint(encoded_target_onto[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1770411515274,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "K4cIBT_jvxqe",
    "outputId": "fe6b70f7-b1f2-4886-b13b-d4ad64a9a67b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded source ontology:\n",
      "{'iri': 'http://mouse.owl#MA_0000001', 'text': 'mouse anatomy  '}\n",
      "Encoded target ontology:\n",
      "{'iri': 'http://human.owl#NCI_C12219',\n",
      " 'text': 'anatomic structure system or substance  '}\n"
     ]
    }
   ],
   "source": [
    "encoder = ConceptParentLightweightEncoder()\n",
    "\n",
    "encoded_source_onto, encoded_target_onto = encoder(\n",
    "        source=dataset['source'],\n",
    "        target=dataset['target']\n",
    ")\n",
    "\n",
    "print(\"Encoded source ontology:\")\n",
    "pprint(encoded_source_onto[0])\n",
    "\n",
    "print(\"Encoded target ontology:\")\n",
    "pprint(encoded_target_onto[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exporter_section"
   },
   "source": [
    "---\n",
    "\n",
    "# 4Ô∏è‚É£. How the ``Exporter`` Module Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exporter_explanation"
   },
   "source": [
    "The **Exporter** module converts computed alignments into standardized formats that can be used by other systems and evaluation benchmarks. It handles format conversion and validation.\n",
    "\n",
    "**Supported Export Formats:**\n",
    "- **RDF/XML**: Standard semantic web format\n",
    "- **SKOS-XL**: Simple Knowledge Organization System\n",
    "- **Alignment Format (EDOAL)**: Standard ontology alignment format\n",
    "- **CSV**: Tabular format for easy inspection\n",
    "- **JSON**: Structured data format\n",
    "\n",
    "**Key Exporter Classes:**\n",
    "- `BaseExporter` - Base exporting functionality\n",
    "- `RDFExporter` - Export to RDF/XML format\n",
    "- `AlignmentFormatExporter` - Export to OAEI alignment format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1770413339672,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "exporter_preparation"
   },
   "outputs": [],
   "source": [
    "from ontoaligner.utils import xmlify\n",
    "\n",
    "# Create sample alignments to export\n",
    "sample_alignments = [\n",
    "    {\n",
    "        'source': 'http://mouse.owl#MA_0002401',\n",
    "        'target': 'http://human.owl#NCI_C52561',\n",
    "        'relation': '=',\n",
    "        'score': 0.95\n",
    "    },\n",
    "    {\n",
    "        'source': 'http://mouse.owl#MA_0000270',\n",
    "        'target': 'http://human.owl#NCI_C33736',\n",
    "        'relation': '=',\n",
    "        'score': 0.87\n",
    "    },\n",
    "    {\n",
    "        'source': 'http://mouse.owl#MA_0001951',\n",
    "        'target': 'http://human.owl#NCI_C12715',\n",
    "        'relation': '=',\n",
    "        'score': 0.92\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1770413343059,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "exporter_alignment_format",
    "outputId": "d17792cd-d27f-4e0a-d032-b7d35d710d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" ?>\n",
      "<rdf:RDF xmlns=\"http://knowledgeweb.semanticweb.org/heterogeneity/alignment\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\">\n",
      "  <Alignment>\n",
      "    <xml>yes</xml>\n",
      "    <level>0</level>\n",
      "    <type>??</type>\n",
      "    <map>\n",
      "      <Cell>\n",
      "        <entity1 rdf:resource=\"http://mouse.owl#MA_0002401\"/>\n",
      "        <entity2 rdf:resource=\"http://human.owl#NCI_C52561\"/>\n",
      "        <relation>=</relation>\n",
      "        <measure rdf:datatype=\"xsd:float\">0.9</measure>\n",
      "      </Cell>\n",
      "    </map>\n",
      "    <map>\n",
      "      <Cell>\n",
      "        <entity1 rdf:resource=\"http://mouse.owl#MA_0000270\"/>\n",
      "        <entity2 rdf:resource=\"http://human.owl#NCI_C33736\"/>\n",
      "        <relation>=</relation>\n",
      "        <measure rdf:datatype=\"xsd:float\">0.8</measure>\n",
      "      </Cell>\n",
      "    </map>\n",
      "    <map>\n",
      "      <Cell>\n",
      "        <entity1 rdf:resource=\"http://mouse.owl#MA_0001951\"/>\n",
      "        <entity2 rdf:resource=\"http://human.owl#NCI_C12715\"/>\n",
      "        <relation>=</relation>\n",
      "        <measure rdf:datatype=\"xsd:float\">0.9</measure>\n",
      "      </Cell>\n",
      "    </map>\n",
      "  </Alignment>\n",
      "</rdf:RDF>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üìÑ Export to XML (RDF Alignment Format)\n",
    "alignment_xml = xmlify.xml_alignment_generator(matchings=sample_alignments)\n",
    "\n",
    "print(alignment_xml)\n",
    "\n",
    "with open(\"alignments.xml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(alignment_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1770413349948,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "exporter_csv"
   },
   "outputs": [],
   "source": [
    "# üßæ Export to JSON\n",
    "import json\n",
    "\n",
    "with open(\"alignments.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sample_alignments, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1770413359024,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "exporter_json"
   },
   "outputs": [],
   "source": [
    "# üìä Export to CSV\n",
    "import csv\n",
    "\n",
    "with open(\"alignments.csv\", \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['source', 'target', 'relation', 'score'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(sample_alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "workflow_section"
   },
   "source": [
    "---\n",
    "\n",
    "# 5Ô∏è‚É£. Putting it all together - A complete workflow with an ``Evaluation``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "workflow_intro"
   },
   "source": [
    "Now let's demonstrate how all modules work together in an end-to-end ontology alignment workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4856,
     "status": "ok",
     "timestamp": 1770413919152,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "workflow_step1",
    "outputId": "969ba576-c7ce-4c9e-b6c0-230d4542aeca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2744it [00:00, 13022.28it/s]\n",
      "3304it [00:00, 9744.22it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9102/9102 [00:00<00:00, 36866.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded dataset info: dict_keys(['dataset-info', 'source', 'target', 'reference'])\n",
      "‚úì Loaded 2743 source entities\n",
      "‚úì Loaded 3304 target entities\n",
      "‚úì Loaded 1516 reference alignments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: PARSER - Load ontologies and alignments\n",
    "from ontoaligner.ontology import GenericOMDataset\n",
    "\n",
    "task = GenericOMDataset()\n",
    "dataset = task.collect(\n",
    "    source_ontology_path=\"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/source.xml\",\n",
    "    target_ontology_path=\"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/target.xml\",\n",
    "    reference_matching_path=\"https://raw.githubusercontent.com/sciknoworg/OntoAligner/main/assets/mouse-human/reference.xml\"\n",
    ")\n",
    "print(f\"‚úì Loaded {len(dataset['source'])} source entities\")\n",
    "print(f\"‚úì Loaded {len(dataset['target'])} target entities\")\n",
    "print(f\"‚úì Loaded {len(dataset['reference'])} reference alignments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1770413482975,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "workflow_step2",
    "outputId": "2d3aaaaa-23df-4ef5-cb47-3b759846d2f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Structured 2743 source entities\n",
      "‚úì Structured 3304 target entities\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: ENCODER - Structure the Input\n",
    "from ontoaligner.encoder import ConceptLightweightEncoder\n",
    "\n",
    "encoder = ConceptLightweightEncoder()\n",
    "encoded_source_onto, encoded_target_onto = encoder(\n",
    "        source=dataset['source'],\n",
    "        target=dataset['target']\n",
    ")\n",
    "\n",
    "print(f\"‚úì Structured {len(encoded_source_onto)} source entities\")\n",
    "print(f\"‚úì Structured {len(encoded_target_onto)} target entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2605,
     "status": "ok",
     "timestamp": 1770413654485,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "workflow_step3",
    "outputId": "ba08a45a-a7f0-47fc-d626-941960bf1753"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2743/2743 [00:02<00:00, 1113.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Found 2159 high-confidence alignments (>0.7)\n",
      "\n",
      "Top 5 alignments:\n",
      "  1. http://mouse.owl#MA_0000001 -> http://human.owl#NCI_C21599 (confidence-score: 0.7200)\n",
      "  2. http://mouse.owl#MA_0000002 -> http://human.owl#NCI_C49799 (confidence-score: 0.8444)\n",
      "  3. http://mouse.owl#MA_0000003 -> http://human.owl#NCI_C12919 (confidence-score: 1.0000)\n",
      "  4. http://mouse.owl#MA_0000004 -> http://human.owl#NCI_C33816 (confidence-score: 1.0000)\n",
      "  5. http://mouse.owl#MA_0000006 -> http://human.owl#NCI_C12418 (confidence-score: 0.8182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: ALIGNER - Define Aligner model and generte the alignments\n",
    "from ontoaligner.aligner import SimpleFuzzySMLightweight\n",
    "\n",
    "model = SimpleFuzzySMLightweight(fuzzy_sm_threshold=0.7)\n",
    "alignments = model.generate(input_data=[encoded_source_onto, encoded_target_onto])\n",
    "\n",
    "\n",
    "print(f\"\\n‚úì Found {len(alignments)} high-confidence alignments (>0.7)\")\n",
    "print(\"\\nTop 5 alignments:\")\n",
    "for i, alignment in enumerate(alignments[:5], 1):\n",
    "    source_id = alignment['source']\n",
    "    target_id = alignment['target']\n",
    "    print(f\"  {i}. {source_id} -> {target_id} (confidence-score: {alignment['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MO_RdwkX4ptW"
   },
   "source": [
    "**Now, lets evaluate the performance of the fuzzy matcher by comparing the predicted matchings with the reference data, before exporting the alignments.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1770413927439,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "zEOoz-vJ4lNx",
    "outputId": "21364b8d-4535-4a92-b635-b8d6a420178f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Report:\n",
      " {\n",
      "    \"intersection\": 1163,\n",
      "    \"precision\": 53.86753126447429,\n",
      "    \"recall\": 76.71503957783641,\n",
      "    \"f-score\": 63.29251700680272,\n",
      "    \"predictions-len\": 2159,\n",
      "    \"reference-len\": 1516\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: EVALUATE - Evaluate the efficency of alignments.\n",
    "from ontoaligner.utils import metrics\n",
    "\n",
    "evaluation = metrics.evaluation_report(\n",
    "    predicts=alignments,\n",
    "    references=dataset['reference']\n",
    ")\n",
    "\n",
    "print(\"Evaluation Report:\\n\", json.dumps(evaluation, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1770414146329,
     "user": {
      "displayName": "Hamed Babaei",
      "userId": "12073215039819409602"
     },
     "user_tz": -60
    },
    "id": "workflow_step5",
    "outputId": "1452c270-23ea-49d6-c5e0-be610e7a8eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Exported to Alignment Format (OAEI standard)\n",
      "  Format: RDF/XML\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: EXPORTER - Export results in a XML format\n",
    "from ontoaligner.utils import xmlify\n",
    "\n",
    "xml_str = xmlify.xml_alignment_generator(alignments)\n",
    "with open(\"alignments.xml\", \"w\", encoding=\"utf-8\") as xml_file:\n",
    "    xml_file.write(xml_str)\n",
    "\n",
    "print(\"‚úì Exported to Alignment Format (OAEI standard)\")\n",
    "print(\"  Format: RDF/XML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "key_takeaways"
   },
   "source": [
    "---\n",
    "\n",
    "# ‚úÖ Key Takeaways\n",
    "\n",
    "1. **Parser Module**: Enables flexible parsing of ontologies from multiple file formats.\n",
    "2. **OMDataset**: Defines an ontology alignment task by loading source and target ontologies together with their reference alignment in a single step.\n",
    "3. **Encoder Module**: Structures and prepares ontology data as input for aligners.\n",
    "4. **Exporter Module**: Produces standardized alignment outputs compatible with OAEI benchmarks.\n",
    "5. **Modularity**: Each component can be used independently or combined to build complete alignment workflows.\n",
    "\n",
    "For more information, visit the [OntoAligner Documentation](https://ontoaligner.readthedocs.io/)\n",
    "\n",
    "-----------------------------------------------------------\n",
    "-----------------------------------------------------------\n",
    "\n",
    "üìÉ Acknowledgement\n",
    "\n",
    "OntoAligner is licensed under [![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n",
    "\n",
    "\n",
    "```bibtex\n",
    "@inproceedings{babaei2025ontoaligner,\n",
    "  title={OntoAligner: A Comprehensive Modular and Robust Python Toolkit for Ontology Alignment},\n",
    "  author={Babaei Giglou, Hamed and D‚ÄôSouza, Jennifer and Karras, Oliver and Auer, S{\\\"o}ren},\n",
    "  booktitle={European Semantic Web Conference},\n",
    "  pages={174--191},\n",
    "  year={2025},\n",
    "  organization={Springer}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NgCSKZA85rL2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
